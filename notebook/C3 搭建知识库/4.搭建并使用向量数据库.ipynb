{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建并使用向量数据库\n",
    "## 一、前序配置\n",
    "本节重点为搭建并使用向量数据库，因此读取数据后我们省去数据处理的环节直入主题，数据清洗等步骤可以参考第三节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md', '../../data_base/knowledge_db/prompt_engineering/2. 提示原则 Guidelines.md', '../../data_base/knowledge_db/prompt_engineering/8. 聊天机器人 Chatbot.md']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 如果你需要通过代理端口访问，你需要如下配置\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ[\"HTTP_PROXY\"] = 'http://127.0.0.1:7890'\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = '../../data_base/knowledge_db'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历文件路径并把实例化的loader存放在loaders里\n",
    "loaders = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == 'md':\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载文件并存储到text\n",
    "texts = []\n",
    "\n",
    "for loader in loaders:\n",
    "    texts.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入后的变量类型为`langchain_core.documents.base.Document`, 文档变量类型同样包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../../data_base/knowledge_db/prompt_engineering/2. 提示原则 Guidelines.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第二章 提示原则\n",
      "\n",
      "如何去使用 Prompt，以充分发挥 LLM 的性能？首先我们需要知道设计 Prompt 的原则，它们是每一个开发者设计 Prompt 所必须知道的基础概念。本章讨论了设计高效 Prompt 的两个关键原则：编写清晰、具体的指令和给予模型充足思考时间。掌握这两点，对创建可靠的语言模型交互尤为重要。\n",
      "\n",
      "首先，Prompt 需要清晰明确地表达需求，提供充足上下文，使语言模型准确理解我们的意图，就像向一个外星人详细解释人类世界一样。过于简略的 Prompt 往往使模型难以把握所要完成的具体任务。\n",
      "\n",
      "其次，让语言模型有充足时间推理也极为关键。就像人类解题一样，匆忙得出的结论多有失误。因此 Prompt 应加入逐步推理的要求，给模型留出充分思考时间，这样生成的结果才更准确可靠。\n",
      "\n",
      "如果 Prompt 在这两点上都作了优化，语言模型就能够尽可能发挥潜力，完成复杂的推理和生成任务。掌握这些 Prompt 设计原则，是开发者取得语言模型应用成功的重要一步。\n",
      "\n",
      "一、原则一 编写清晰、具体的指令\n",
      "\n",
      "亲爱的读者，在与语言模型交互时，您需要牢记一点:以清晰、具体的方式表达您的需求。假设您面前坐着一位来自外星球的新朋友，其对人类语言和常识都一无所知。在这种情况下，您需要把想表达的意图讲得非常明确，不要有任何歧义。同样的，在提供 Prompt 的时候，也要以足够详细和容易理解的方式，把您的需求与上下文说清楚。\n",
      "\n",
      "并不是说 Prompt 就必须非常短小简洁。事实上，在许多情况下，更长、更复杂的 Prompt 反而会让语言模型更容易抓住关键点，给出符合预期的回复。原因在于，复杂的 Prompt 提供了更丰富的上下文和细节，让模型可以更准确地把握所需的操作和响应方式。\n",
      "\n",
      "所以，记住用清晰、详尽的语言表达 Prompt，就像在给外星人讲解人类世界一样，“Adding more context helps the model understand you better.”。\n",
      "\n",
      "从该原则出发，我们提供几个设计 Prompt 的技巧。\n",
      "\n",
      "1.1 使用分隔符清晰地表示输入的不同部分\n",
      "\n",
      "在编写 Prompt 时，我们可以使用各种标点符号作为“分隔符”，将不同的文本部分区分开来。\n",
      "\n",
      "分隔符就像是 Prompt 中的墙，将不同的指令、上下文、输入隔开，避免意外的混淆。你可以选择用 ```，\"\"\"，< >，<tag> </tag>，: 等做分隔符，只要能明确起到隔断作用即可。\n",
      "\n",
      "使用分隔符尤其重要的是可以防止 提示词注入（Prompt Rejection）。什么是提示词注入？就是用户输入的文本可能包含与你的预设 Prompt 相冲突的内容，如果不加分隔，这些输入就可能“注入”并操纵语言模型，导致模型产生毫无关联的乱七八糟的输出。\n",
      "\n",
      "在以下的例子中，我们给出一段话并要求 GPT 进行总结，在该示例中我们使用 ``` 来作为分隔符。\n",
      "\n",
      "```python\n",
      "from tool import get_completion\n",
      "\n",
      "text = f\"\"\"\n",
      "您应该提供尽可能清晰、具体的指示，以表达您希望模型执行的任务。\\\n",
      "这将引导模型朝向所需的输出，并降低收到无关或不正确响应的可能性。\\\n",
      "不要将写清晰的提示词与写简短的提示词混淆。\\\n",
      "在许多情况下，更长的提示词可以为模型提供更多的清晰度和上下文信息，从而导致更详细和相关的输出。\n",
      "\"\"\"\n",
      "\n",
      "需要总结的文本内容\n",
      "\n",
      "prompt = f\"\"\"\n",
      "把用三个反引号括起来的文本总结成一句话。\n",
      "{text}\n",
      "\"\"\"\n",
      "\n",
      "指令内容，使用 ``` 来分隔指令和待总结的内容\n",
      "\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "1.2 寻求结构化的输出\n",
      "\n",
      "有时候我们需要语言模型给我们一些结构化的输出，而不仅仅是连续的文本。\n",
      "\n",
      "什么是结构化输出呢？就是按照某种格式组织的内容，例如JSON、HTML等。这种输出非常适合在代码中进一步解析和处理。例如，您可以在 Python 中将其读入字典或列表中。\n",
      "\n",
      "在以下示例中，我们要求 GPT 生成三本书的标题、作者和类别，并要求 GPT 以 JSON 的格式返回给我们，为便于解析，我们指定了 Json 的键。\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "请生成包括书名、作者和类别的三本虚构的、非真实存在的中文书籍清单，\\\n",
      "并以 JSON 格式提供，其中包含以下键:book_id、title、author、genre。\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "\n",
      "```\n",
      "\n",
      "1.3 要求模型检查是否满足条件\n",
      "\n",
      "如果任务包含不一定能满足的假设（条件），我们可以告诉模型先检查这些假设，如果不满足，则会指出并停止执行后续的完整流程。您还可以考虑可能出现的边缘情况及模型的应对，以避免意外的结果或错误发生。\n",
      "\n",
      "在如下示例中，我们将分别给模型两段文本，分别是制作茶的步骤以及一段没有明确步骤的文本。我们将要求模型判断其是否包含一系列指令，如果包含则按照给定格式重新编写指令，不包含则回答“未提供步骤”。\n",
      "\n",
      "```python\n",
      "\n",
      "满足条件的输入（text中提供了步骤）\n",
      "\n",
      "text_1 = f\"\"\"\n",
      "泡一杯茶很容易。首先，需要把水烧开。\\\n",
      "在等待期间，拿一个杯子并把茶包放进去。\\\n",
      "一旦水足够热，就把它倒在茶包上。\\\n",
      "等待一会儿，让茶叶浸泡。几分钟后，取出茶包。\\\n",
      "如果您愿意，可以加一些糖或牛奶调味。\\\n",
      "就这样，您可以享受一杯美味的茶了。\n",
      "\"\"\"\n",
      "prompt = f\"\"\"\n",
      "您将获得由三个引号括起来的文本。\\\n",
      "如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：\n",
      "\n",
      "第一步 - ...\n",
      "第二步 - …\n",
      "…\n",
      "第N步 - …\n",
      "\n",
      "如果文本中不包含一系列的指令，则直接写“未提供步骤”。\"\n",
      "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(\"Text 1 的总结:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "上述示例中，模型可以很好地识别一系列的指令并进行输出。在接下来一个示例中，我们将提供给模型没有预期指令的输入，模型将判断未提供步骤。\n",
      "\n",
      "```python\n",
      "\n",
      "不满足条件的输入（text中未提供预期指令）\n",
      "\n",
      "text_2 = f\"\"\"\n",
      "今天阳光明媚，鸟儿在歌唱。\\\n",
      "这是一个去公园散步的美好日子。\\\n",
      "鲜花盛开，树枝在微风中轻轻摇曳。\\\n",
      "人们外出享受着这美好的天气，有些人在野餐，有些人在玩游戏或者在草地上放松。\\\n",
      "这是一个完美的日子，可以在户外度过并欣赏大自然的美景。\n",
      "\"\"\"\n",
      "prompt = f\"\"\"\n",
      "您将获得由三个引号括起来的文本。\\\n",
      "如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：\n",
      "\n",
      "第一步 - ...\n",
      "第二步 - …\n",
      "…\n",
      "第N步 - …\n",
      "\n",
      "如果文本中不包含一系列的指令，则直接写“未提供步骤”。\"\n",
      "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(\"Text 2 的总结:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "1.4 提供少量示例\n",
      "\n",
      "\"Few-shot\" prompting，即在要求模型执行实际任务之前，给模型一两个已完成的样例，让模型了解我们的要求和期望的输出样式。\n",
      "\n",
      "例如，在以下的样例中，我们先给了一个祖孙对话样例，然后要求模型用同样的隐喻风格回答关于“韧性”的问题。这就是一个少样本样例，它能帮助模型快速抓住我们要的语调和风格。\n",
      "\n",
      "利用少样本样例，我们可以轻松“预热”语言模型，让它为新的任务做好准备。这是一个让模型快速上手新任务的有效策略。\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "您的任务是以一致的风格回答问题。\n",
      "\n",
      "<孩子>: 请教我何为耐心。\n",
      "\n",
      "<祖父母>: 挖出最深峡谷的河流源于一处不起眼的泉眼；最宏伟的交响乐从单一的音符开始；最复杂的挂毯以一根孤独的线开始编织。\n",
      "\n",
      "<孩子>: 请教我何为韧性。\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "二、原则二 给模型时间去思考\n",
      "\n",
      "在设计 Prompt 时，给予语言模型充足的推理时间非常重要。语言模型与人类一样，需要时间来思考并解决复杂问题。如果让语言模型匆忙给出结论，其结果很可能不准确。例如，若要语言模型推断一本书的主题，仅提供简单的书名和一句简介是不足够的。这就像让一个人在极短时间内解决困难的数学题，错误在所难免。\n",
      "\n",
      "相反，我们应通过 Prompt 指引语言模型进行深入思考。可以要求其先列出对问题的各种看法，说明推理依据，然后再得出最终结论。在 Prompt 中添加逐步推理的要求，能让语言模型投入更多时间逻辑思维，输出结果也将更可靠准确。\n",
      "\n",
      "综上所述，给予语言模型充足的推理时间，是 Prompt Engineering 中一个非常重要的设计原则。这将大大提高语言模型处理复杂问题的效果，也是构建高质量 Prompt 的关键之处。开发者应注意给模型留出思考空间，以发挥语言模型的最大潜力。\n",
      "\n",
      "2.1 指定完成任务所需的步骤\n",
      "\n",
      "接下来我们将通过给定一个复杂任务，给出完成该任务的一系列步骤，来展示这一策略的效果。\n",
      "\n",
      "首先我们描述了杰克和吉尔的故事，并给出提示词执行以下操作：首先，用一句话概括三个反引号限定的文本。第二，将摘要翻译成英语。第三，在英语摘要中列出每个名称。第四，输出包含以下键的 JSON 对象：英语摘要和人名个数。要求输出以换行符分隔。\n",
      "\n",
      "```python\n",
      "text = f\"\"\"\n",
      "在一个迷人的村庄里，兄妹杰克和吉尔出发去一个山顶井里打水。\\\n",
      "他们一边唱着欢乐的歌，一边往上爬，\\\n",
      "然而不幸降临——杰克绊了一块石头，从山上滚了下来，吉尔紧随其后。\\\n",
      "虽然略有些摔伤，但他们还是回到了温馨的家中。\\\n",
      "尽管出了这样的意外，他们的冒险精神依然没有减弱，继续充满愉悦地探索。\n",
      "\"\"\"\n",
      "\n",
      "example 1\n",
      "\n",
      "prompt_1 = f\"\"\"\n",
      "执行以下操作：\n",
      "1-用一句话概括下面用三个反引号括起来的文本。\n",
      "2-将摘要翻译成英语。\n",
      "3-在英语摘要中列出每个人名。\n",
      "4-输出一个 JSON 对象，其中包含以下键：english_summary，num_names。\n",
      "\n",
      "请用换行符分隔您的答案。\n",
      "\n",
      "Text:\n",
      "{text}\n",
      "\"\"\"\n",
      "response = get_completion(prompt_1)\n",
      "print(\"prompt 1:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "上述输出仍然存在一定问题，例如，键“姓名”会被替换为法语（译注：在英文原版中，要求从英语翻译到法语，对应指令第三步的输出为 'Noms:'，为Name的法语，这种行为难以预测，并可能为导出带来困难）\n",
      "\n",
      "因此，我们将Prompt加以改进，该 Prompt 前半部分不变，同时确切指定了输出的格式。\n",
      "\n",
      "```python\n",
      "prompt_2 = f\"\"\"\n",
      "1-用一句话概括下面用<>括起来的文本。\n",
      "2-将摘要翻译成英语。\n",
      "3-在英语摘要中列出每个名称。\n",
      "4-输出一个 JSON 对象，其中包含以下键：English_summary，num_names。\n",
      "\n",
      "请使用以下格式：\n",
      "文本：<要总结的文本>\n",
      "摘要：<摘要>\n",
      "翻译：<摘要的翻译>\n",
      "名称：<英语摘要中的名称列表>\n",
      "输出 JSON：<带有 English_summary 和 num_names 的 JSON>\n",
      "\n",
      "Text: <{text}>\n",
      "\"\"\"\n",
      "response = get_completion(prompt_2)\n",
      "print(\"\\nprompt 2:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "2.2 指导模型在下结论之前找出一个自己的解法\n",
      "\n",
      "在设计 Prompt 时，我们还可以通过明确指导语言模型进行自主思考，来获得更好的效果。\n",
      "\n",
      "举个例子，假设我们要语言模型判断一个数学问题的解答是否正确。仅仅提供问题和解答是不够的，语言模型可能会匆忙做出错误判断。\n",
      "\n",
      "相反，我们可以在 Prompt 中先要求语言模型自己尝试解决这个问题，思考出自己的解法，然后再与提供的解答进行对比，判断正确性。这种先让语言模型自主思考的方式，能帮助它更深入理解问题，做出更准确的判断。\n",
      "\n",
      "接下来我们会给出一个问题和一份来自学生的解答，要求模型判断解答是否正确：\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "判断学生的解决方案是否正确。\n",
      "\n",
      "问题:\n",
      "我正在建造一个太阳能发电站，需要帮助计算财务。\n",
      "\n",
      "学生的解决方案：\n",
      "设x为发电站的大小，单位为平方英尺。\n",
      "费用：\n",
      "\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "但是注意，学生的解决方案实际上是错误的。（维护费用项100x应为10x，总费用450x应为360x）\n",
      "\n",
      "我们可以通过指导模型先自行找出一个解法来解决这个问题。\n",
      "\n",
      "在接下来这个 Prompt 中，我们要求模型先自行解决这个问题，再根据自己的解法与学生的解法进行对比，从而判断学生的解法是否正确。同时，我们给定了输出的格式要求。通过拆分任务、明确步骤，让模型有更多时间思考，有时可以获得更准确的结果。在这个例子中，学生的答案是错误的，但如果我们没有先让模型自己计算，那么可能会被误导以为学生是正确的。\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "请判断学生的解决方案是否正确，请通过如下步骤解决这个问题：\n",
      "\n",
      "步骤：\n",
      "\n",
      "使用以下格式：\n",
      "\n",
      "问题：\n",
      "\n",
      "学生的解决方案：\n",
      "\n",
      "实际解决方案和步骤：\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "三、局限性\n",
      "\n",
      "开发大模型相关应用时请务必铭记：\n",
      "\n",
      "虚假知识：模型偶尔会生成一些看似真实实则编造的知识\n",
      "\n",
      "在开发与应用语言模型时，需要注意它们可能生成虚假信息的风险。尽管模型经过大规模预训练，掌握了丰富知识，但它实际上并没有完全记住所见的信息，难以准确判断自己的知识边界，可能做出错误推断。若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉”(Hallucination)，是语言模型的一大缺陷。\n",
      "\n",
      "如下示例展示了大模型的幻觉。我们要求告诉我们华为公司生产的 GT Watch 运动手表 产品的信息，事实上，这个公司是真实存在的，但产品是编造的，而模型一本正经地提供了它编造的知识，而且迷惑性很强。\n",
      "\n",
      "python\n",
      "prompt = f\"\"\"\n",
      "告诉我华为公司生产的GT Watch运动手表的相关信息\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "\n",
      "语言模型生成虚假信息的“幻觉”问题，是使用与开发语言模型时需要高度关注的风险。由于幻觉信息往往令人无法辨别真伪，开发者必须警惕并尽量避免它的产生。\n",
      "\n",
      "目前 OpenAI 等公司正在积极研究解决语言模型的幻觉问题。在技术得以进一步改进之前，开发者可以通过Prompt设计减少幻觉发生的可能。例如，可以先让语言模型直接引用文本中的原句，然后再进行解答。这可以追踪信息来源，降低虚假内容的风险。\n",
      "\n",
      "综上，语言模型的幻觉问题事关应用的可靠性与安全性。开发者有必要认识到这一缺陷（注：截至2023年7月），并采取Prompt优化等措施予以缓解，以开发出更加可信赖的语言模型应用。这也将是未来语言模型进化的重要方向之一。\n",
      "\n",
      "注意：\n",
      "\n",
      "关于反斜杠使用的说明：在本教程中，我们使用反斜杠 \\ 来使文本适应屏幕大小以提高阅读体验，而没有用换行符 \\n 。GPT-3 并不受换行符（newline characters）的影响，但在您调用其他大模型时，需额外考虑换行符是否会影响模型性能。\n",
      "\n",
      "四、英文原版 Prompt\n",
      "\n",
      "1.1 使用分隔符清晰地表示输入的不同部分\n",
      "\n",
      "python\n",
      "text = f\"\"\"\n",
      "You should express what you want a model to do by \\ \n",
      "providing instructions that are as clear and \\ \n",
      "specific as you can possibly make them. \\ \n",
      "This will guide the model towards the desired output, \\ \n",
      "and reduce the chances of receiving irrelevant \\ \n",
      "or incorrect responses. Don't confuse writing a \\ \n",
      "clear prompt with writing a short prompt. \\ \n",
      "In many cases, longer prompts provide more clarity \\ \n",
      "and context for the model, which can lead to \\ \n",
      "more detailed and relevant outputs.\n",
      "\"\"\"\n",
      "prompt = f\"\"\"\n",
      "Summarize the text delimited by triple backticks \\ \n",
      "into a single sentence.{text}\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "\n",
      "1.2 寻求结构化的输出\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "Generate a list of three made-up book titles along \\ \n",
      "with their authors and genres. \n",
      "Provide them in JSON format with the following keys: \n",
      "book_id, title, author, genre.\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "\n",
      "```\n",
      "\n",
      "1.3 要求模型检查是否满足条件\n",
      "\n",
      "```python\n",
      "text_1 = f\"\"\"\n",
      "Making a cup of tea is easy! First, you need to get some \\ \n",
      "water boiling. While that's happening, \\ \n",
      "grab a cup and put a tea bag in it. Once the water is \\ \n",
      "hot enough, just pour it over the tea bag. \\ \n",
      "Let it sit for a bit so the tea can steep. After a \\ \n",
      "few minutes, take out the tea bag. If you \\ \n",
      "like, you can add some sugar or milk to taste. \\ \n",
      "And that's it! You've got yourself a delicious \\ \n",
      "cup of tea to enjoy.\n",
      "\"\"\"\n",
      "prompt = f\"\"\"\n",
      "You will be provided with text delimited by triple quotes. \n",
      "If it contains a sequence of instructions, \\ \n",
      "re-write those instructions in the following format:\n",
      "\n",
      "Step 1 - ...\n",
      "Step 2 - …\n",
      "…\n",
      "Step N - …\n",
      "\n",
      "If the text does not contain a sequence of instructions, \\ \n",
      "then simply write \\\"No steps provided.\\\"\n",
      "\n",
      "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(\"Completion for Text 1:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "```python\n",
      "text_2 = f\"\"\"\n",
      "The sun is shining brightly today, and the birds are \\\n",
      "singing. It's a beautiful day to go for a \\ \n",
      "walk in the park. The flowers are blooming, and the \\ \n",
      "trees are swaying gently in the breeze. People \\ \n",
      "are out and about, enjoying the lovely weather. \\ \n",
      "Some are having picnics, while others are playing \\ \n",
      "games or simply relaxing on the grass. It's a \\ \n",
      "perfect day to spend time outdoors and appreciate the \\ \n",
      "beauty of nature.\n",
      "\"\"\"\n",
      "prompt = f\"\"\"You will be provided with text delimited by triple quotes. \n",
      "If it contains a sequence of instructions, \\ \n",
      "re-write those instructions in the following format:\n",
      "Step 1 - ...\n",
      "Step 2 - …\n",
      "…\n",
      "Step N - …\n",
      "\n",
      "If the text does not contain a sequence of instructions, \\ \n",
      "then simply write \\\"No steps provided.\\\"\n",
      "\n",
      "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(\"Completion for Text 2:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "1.4 提供少量示例（少样本提示词，Few-shot prompting）\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "Your task is to answer in a consistent style.\n",
      "\n",
      ": Teach me about patience.\n",
      "\n",
      ": The river that carves the deepest \\ \n",
      "valley flows from a modest spring; the \\ \n",
      "grandest symphony originates from a single note; \\ \n",
      "the most intricate tapestry begins with a solitary thread.\n",
      "\n",
      ": Teach me about resilience.\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "2.1 指定完成任务所需的步骤\n",
      "\n",
      "```python\n",
      "text = f\"\"\"\n",
      "In a charming village, siblings Jack and Jill set out on \\ \n",
      "a quest to fetch water from a hilltop \\ \n",
      "well. As they climbed, singing joyfully, misfortune \\ \n",
      "struck—Jack tripped on a stone and tumbled \\ \n",
      "down the hill, with Jill following suit. \\ \n",
      "Though slightly battered, the pair returned home to \\ \n",
      "comforting embraces. Despite the mishap, \\ \n",
      "their adventurous spirits remained undimmed, and they \\ \n",
      "continued exploring with delight.\n",
      "\"\"\"\n",
      "\n",
      "example 1\n",
      "\n",
      "prompt_1 = f\"\"\"\n",
      "Perform the following actions: \n",
      "1 - Summarize the following text delimited by triple \\\n",
      "backticks with 1 sentence.\n",
      "2 - Translate the summary into French.\n",
      "3 - List each name in the French summary.\n",
      "4 - Output a json object that contains the following \\\n",
      "keys: french_summary, num_names.\n",
      "\n",
      "Separate your answers with line breaks.\n",
      "\n",
      "Text:\n",
      "{text}\n",
      "\"\"\"\n",
      "response = get_completion(prompt_1)\n",
      "print(\"Completion for prompt 1:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "```python\n",
      "prompt_2 = f\"\"\"\n",
      "Your task is to perform the following actions: \n",
      "1 - Summarize the following text delimited by <> with 1 sentence.\n",
      "2 - Translate the summary into French.\n",
      "3 - List each name in the French summary.\n",
      "4 - Output a json object that contains the \n",
      "following keys: french_summary, num_names.\n",
      "\n",
      "Use the following format:\n",
      "Text: \n",
      "Summary: \n",
      "Translation: \n",
      "Names: \n",
      "Output JSON:\n",
      "\n",
      "Text: <{text}>\n",
      "\"\"\"\n",
      "response = get_completion(prompt_2)\n",
      "print(\"\\nCompletion for prompt 2:\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "2.2 指导模型在下结论之前找出一个自己的解法\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "Determine if the student's solution is correct or not.\n",
      "\n",
      "Question:\n",
      "I'm building a solar power installation and I need \\\n",
      " help working out the financials. \n",
      "- Land costs $100 / square foot\n",
      "- I can buy solar panels for $250 / square foot\n",
      "- I negotiated a contract for maintenance that will cost \\ \n",
      "me a flat $100k per year, and an additional $10 / square \\\n",
      "foot\n",
      "What is the total cost for the first year of operations \n",
      "as a function of the number of square feet.\n",
      "\n",
      "Student's Solution:\n",
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 100x\n",
      "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "```python\n",
      "prompt = f\"\"\"\n",
      "Your task is to determine if the student's solution \\\n",
      "is correct or not.\n",
      "To solve the problem do the following:\n",
      "- First, work out your own solution to the problem. \n",
      "- Then compare your solution to the student's solution \\ \n",
      "and evaluate if the student's solution is correct or not. \n",
      "Don't decide if the student's solution is correct until \n",
      "you have done the problem yourself.\n",
      "\n",
      "Use the following format:\n",
      "Question:\n",
      "question here\n",
      "Student's solution:\n",
      "student's solution here\n",
      "Actual solution:\n",
      "steps to work out the solution and your solution here\n",
      "Is the student's solution the same as actual solution \\\n",
      "just calculated:\n",
      "yes or no\n",
      "Student grade:\n",
      "correct or incorrect\n",
      "\n",
      "Question:\n",
      "I'm building a solar power installation and I need help \\\n",
      "working out the financials. \n",
      "- Land costs $100 / square foot\n",
      "- I can buy solar panels for $250 / square foot\n",
      "- I negotiated a contract for maintenance that will cost \\\n",
      "me a flat $100k per year, and an additional $10 / square \\\n",
      "foot\n",
      "What is the total cost for the first year of operations \\\n",
      "as a function of the number of square feet. \n",
      "Student's solution:\n",
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 100x\n",
      "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
      "Actual solution:\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "\n",
      "3.1 幻觉\n",
      "\n",
      "python\n",
      "prompt = f\"\"\"\n",
      "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n"
     ]
    }
   ],
   "source": [
    "text = texts[1]\n",
    "print(f\"每一个元素的类型：{type(text)}.\", \n",
    "    f\"该文档的描述性数据：{text.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{text.page_content[0:]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、构建Chroma向量库\n",
    "\n",
    "Langchain 集成了超过 30 个不同的向量存储库。我们选择 Chroma 是因为它轻量级且数据存储在内存中，这使得它非常容易启动和开始使用。\n",
    "\n",
    "LangChain 可以直接使用 OpenAI 和百度千帆的 Embedding，同时，我们也可以针对其不支持的 Embedding API 进行自定义，例如，我们可以基于 LangChain 提供的接口，封装一个 zhupuai_embedding，来将智谱的 Embedding API 接入到 LangChain 中。在本章的[附LangChain自定义Embedding封装讲解](./附LangChain自定义Embedding封装讲解.ipynb)中，我们以智谱 Embedding API 为例，介绍了如何将其他 Embedding API 封装到 LangChain\n",
    "中，欢迎感兴趣的读者阅读。\n",
    "\n",
    "**注：如果你使用智谱 API，你可以参考讲解内容实现封装代码，也可以直接使用我们已经封装好的代码[zhipuai_embedding.py](./zhipuai_embedding.py)，将该代码同样下载到本 Notebook 的同级目录，就可以直接导入我们封装的函数。在下面的代码 Cell 中，我们默认使用了智谱的 Embedding，将其他两种 Embedding 使用代码以注释的方法呈现，如果你使用的是百度 API 或者 OpenAI API，可以根据情况来使用下方 Cell 中的代码。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint\n",
    "\n",
    "embedding = QianfanEmbeddingsEndpoint()\n",
    "# 定义持久化路径\n",
    "persist_directory = '../../data_base/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '../../data_base/vector_db/chroma'  # 删除旧的数据库文件（如果文件夹中有文件的话），windows电脑请手动删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [06-26 19:52:17] openapi_requestor.py:316 [t:139787657803264]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[0:5], # 为了速度，只选择前 20 个切分的 doc 进行生成；使用千帆时因QPS限制，建议选择前 5 个doc\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之后，我们要确保通过运行 vectordb.persist 来持久化向量数据库，以便我们在未来的课程中使用。\n",
    "\n",
    "让我们保存它，以便以后使用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chroma.sqlite3', '160b7709-d3d4-4f36-a583-f7fbd2d1daca']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：5\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、向量检索\n",
    "### 3.1 相似度检索\n",
    "Chroma的相似度搜索使用的是余弦距离，即：\n",
    "$$\n",
    "similarity = cos(A, B) = \\frac{A \\cdot B}{\\parallel A \\parallel \\parallel B \\parallel} = \\frac{\\sum_1^n a_i b_i}{\\sqrt{\\sum_1^n a_i^2}\\sqrt{\\sum_1^n b_i^2}}\n",
    "$$\n",
    "其中$a_i$、$b_i$分别是向量$A$、$B$的分量。\n",
    "\n",
    "当你需要数据库返回严谨的按余弦相似度排序的结果时可以使用`similarity_search`函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"什么是大语言模型\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [06-26 19:54:38] openapi_requestor.py:316 [t:139787657803264]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "sim_docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 Deep\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforce\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MMR检索\n",
    "如果只考虑检索出内容的相关性会导致内容过于单一，可能丢失重要信息。\n",
    "\n",
    "最大边际相关性 (`MMR, Maximum marginal relevance`) 可以帮助我们在保持相关性的同时，增加内容的丰富度。\n",
    "\n",
    "核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。这样可以在保持相关性的同时，增加内容的多样性，避免过于单一的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [06-24 16:46:17] openapi_requestor.py:316 [t:139797298062848]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n"
     ]
    }
   ],
   "source": [
    "mmr_docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 检索到的第0个内容: \n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 Deep\n",
      "--------------\n",
      "MMR 检索到的第1个内容: \n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforce\n",
      "--------------\n",
      "MMR 检索到的第2个内容: \n",
      "第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Larg\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR 检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_universe_2.x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
